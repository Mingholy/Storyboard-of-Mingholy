---
title:  "Linux内核 思考题"
date:   2015-11-02 20:30:00
cover: "2.jpg"
tags:
    - Linux
    - OS
category: "Linux"
---
# 1
>**为什么计算机启动最开始的时候执行的是BIOS代码而不是操作系统自身的代码？**

因为开机加电的一瞬间，内存中没有程序。而CPU中的逻辑电路被设计成运行内存中的程序，没有能力直接从软盘中运行操作系统。要想运行操作系统，必须通过BIOS将操作系统程序加载到内存中。因此需要首先执行BIOS代码。

# 2
>**为什么BIOS只加载了一个扇区，后续扇区却是由bootsect代码加载？为什么BIOS没有把所有需要加载的扇区都加载？**

因为不同的计算机可能具有不同的BIOS，而一台计算机也可能安装不同的操作系统。为了使BIOS与操作系统能够协同工作，现行的解决方法是“两头约定”和“定位识别”。“约定”操作系统的设计者必须把最开始执行的程序固定在启动扇区，即软盘0盘面0磁道1扇区。“定位识别”是指BIOS一旦接到启动操作系统的命令，就只从上述规定的启动扇区加载代码到0x07c00位置。之后的代码由于不同操作系统设计的内容不同，加载它们的时间、内容也不同，BIOS不能也没有必要来承担后续代码加载的工作，而是交由操作系统代码本身来执行，这就确保了同一台计算机能够正确运行不同的操作系统。

# 3
>**为什么BIOS把bootsect加载到0x07c00，而不是0x00000？加载后又马上挪到0x90000处，是何道理？为什么不一次加载到位？**

0x00000之后的1KB用来存放中断向量表，再之后的256B构建了BIOS数据区。
0x07c00是由BIOS根据“两头约定”和“定位识别”原则确定的。加载后复制自身到0x90000是操作系统本身代码的执行，是操作系统的行为，代表着操作系统开始按照自己的意图规划内存。加载操作系统代码需要遵守“两头约定”和“定位识别”原则，由BIOS来执行。不能在操作系统还未加载的时候就先行决定。

# 4
>**bootsect、setup、head程序之间是怎么衔接的？给出代码证据。**

首先BIOS加载bootsect。bootsect通过load_setup中
{% codeblock lang:gas %}
    mov dx, #0x0000
    mov cx, #0x0002
    mov bx, #0x0200
    mov ax, #0x0200 + SETUPLEN ;SETUPLEN 为4
    int 0x13
{% endcodeblock %}      
读入setup程序的4个扇区。接着继续加载以`head.s`开头的system模块。加载完毕后通过
{% codeblock lang:gas %}
    jmpi 0, SETUPSEG
{% endcodeblock %}
执行setup代码。在setup程序进行了一系列实模式-保护模式过渡准备工作之后，通过GDT来确定`head.s`的位置并执行它
{% codeblock lang:gas %}
    jmpi 0, 8
{% endcodeblock %}
这里将`8`看成`1000`

>int 0x19中断指向的中断服务程序是由BIOS设计好的，用来加载bootsect。`bootsect.s`中load_setup用来加载setup
{% codeblock lang:gas %}
    load_setup:
    mov dx, #0x0000
    mov cx, #0x0002
    mov bx, #0x0200
    mov ax, #0x0200 + SETUPLEN ;SETUPLEN 为4
    int 0x13
    jnc ok_load_setup
    mov dx, #0x0000
    mov ax, #0x0000
    int 0x13
    j load_setup
{% endcodeblock %}
指定了系统要读盘的位置和扇区数之后，转入int 0x13将setup的4个扇区代码读入。
在bootsect接着加载system模块进内存之后，通过
{% codeblock lang:gas %}
     jmpi 0, SETUPSEG
{% endcodeblock %}  
开始继续执行setup程序代码。setup关闭中断，移动内核程序到内存起始位置覆盖BIOS，设置中断描述符表（IDT）和全局描述符表（GDT），将中断向量表的形式转化为中断描述符。接着打开A20，得到32位线性地址空间。重编程8259A可编程中断控制器，重新映射中断号，解决了原中断号与Intel内部中断冲突的问题。接下来将CR0寄存器第0位置1,**开启保护模式**。进入保护模式后，就需要根据GDT来确定后续执行程序的位置。
{% codeblock lang:gas %}
    jmpi 0, 8
{% endcodeblock %}
将8看成1000，表示0特权级下，0表（0位GDT，1位LDT）标号为1的项，即第二项。得到段基址为0x00000000,偏移为0。即system模块中的`head.s`。

# 5
>**setup程序里的cli是为了什么？**

关闭中断，避免中断在复制内核程序、由实模式中断向量表过渡到保护模式中断描述符表时介入。这是为了在实模式中断机制失效而保护模式中断机制尚未建立时，防止进入中断造成系统崩溃。

# 6
>**setup程序的最后是jmpi 0,8 为什么这个8不能简单的当作阿拉伯数字8看待？**

“8”是保护模式下的段选择符，用于选择描述符表和描述符表项以及所要求的特权级。实际上此处的8应理解为0x00008。16位段描述符中高13位为索引，低3位为属性。即“8”代表1000,1为表中项序号，即表中第二项。之后的1位0代表所选择的表，0即GDT；末两位00代表段特权级，即0特权级。

# 7
>**打开A20和打开pe究竟是什么关系，保护模式不就是32位的吗？为什么还要打开A20？有必要吗？**

打开A20实际上是扩展了CPU的寻址空间，由实模式的16位扩大到保护模式的32位。但是此时仍然是保护模式，直至`setup.s`将CR0寄存器第0位置1。之后才是真正的32位保护模式。

# 8
>**Linux是用C语言写的，为什么没有从main函数开始，而是先运行3个汇编程序，道理何在？**

从main函数开始执行是一般应用程序的惯例，其实现需要编译器和操作系统为其完成一系列的支撑工作；而Linux是操作系统程序，是最底层的管理和支撑程序，没有其他程序为其执行做支撑，上电时只能在实模式下通过执行3个汇编程序完成向32位模式的转变，之后才可能执行main函数。40页

# 9
>**为什么不用call，而是用ret“调用”main函数？画出调用路线图，给出代码证据。**

因为在由head程序向main函数跳转时，是不需要main函数返回的；这是由于main函数已经是最底层的函数了，没有更底层的支撑函数支持其返回。所以Linux采用ret指令，模拟函数返回，跳转到main函数去执行。  38页

# 10
>**保护模式的“保护”体现在哪里？**


*   保护模式下，对寄存器和内存空间的访问有等级限制，这样防止了用户程序任意串改系统代码。例如，只有在0特权级下才能对控制寄存器进行读写，而在其他特权级下，这种操作是不允许的
*   采用分页机制，用户进程对内存的读写使用的是线性地址，即基址+偏移
402页

# 11
>**特权级的目的和意义是什么？为什么特权级是基于段的？**

特权级是操作系统为了更好的管理内存空间而设的，提高了系统的安全性。通过段，系统划分了内核代码段、内核数据段、用户代码段和用户数据段等不同的数据段，有些段是系统专享的，有些是和用户程序共享的，因此就有特权级的概念。 398~405页

# 12
>**在setup程序里曾经设置过一次gdt，为什么在head程序中将其废弃，又重新设置了一个？为什么折腾两次，而不是一次搞好？**

30页

# 13
>**在head程序执行结束的时候，在idt的前面有184个字节的head程序的剩余代码，剩余了什么？为什么要剩余？**

通过运行Linux-0.11代码，可以看到剩余的代码是标号after_page_tables之后head程序中的代码。因为head程序共占用25KB+184B的内存空间，系统在建立好分页机制和GDT、IDT之后，在内存空间0x05400-0x54b8处留有184B的空间未使用，因此产生了剩余。

# 14
>**进程0的task_struct在哪？具体内容是什么？给出代码证据。**

在内核数据段。进程0的管理结构task_struct的母本在代码设计阶段就视线设计好了，直接编译加载进内核数据段。内容有状态、信号、pid、alarm、ldt、tss等管理该进程所需的数据。代码证据：
{% codeblock lang:c %}
Sched.c:
  uniontask_union {
  structtask_struct task;
  char stack[PAGE_SIZE];
  };
  static union task_unioninit_task = {INIT_TASK,};
{% endcodeblock %}
{% codeblock lang:c %}
Sched.h:
  #define INIT_TASK \
  /* state etc */ { 0,15,15, \
  /* signals */ 0,{ {},},0, \
  /* ec,brk... */ 0,0,0,0,0,0, \
  /* pid etc.. */ 0,-1,0,0,0, \
  /* uidetc */ 0,0,0,0,0,0, \
  /* alarm */ 0,0,0,0,0,0, \
  /* math */ 0, \
  /* fs info */  -1,0022,NULL,NULL,NULL,0, \
  /* filp */ {NULL,}\, \
  { \
  {0,0}, \
  /* ldt */ {0x9f,0xc0fa00}, \
  {0x9f,0xc0f200}, \
  }, \
  /*tss*/ \{0,PAGE_SIZE+(long)&init_task,0x10,0,0,0,0,(long)&pg_dir,\
  0,0,0,0,0,0,0,0, \
  0,0,0x17,0x17,0x17,0x17,0x17,0x17, \
  _LDT(0),0x80000000, \
  {} \
  }, \
  }
{% endcodeblock %}

# 15
>**进程0创建进程1时，为进程1建立了自己的task_struct、内核栈，第一个页表，分别位于物理内存16MB的顶端倒数第一页、第二页。请问，这个了页究竟占用的是谁的线性地址空间，内核、进程0、进程1、还是没有占用任何线性地址空间（直接从物理地址分配）？说明理由并给出代码证据。**

两次都是通过调用get_free_page()在物理内存里申请一个物理页，由于在head.s中决定内核的物理地址和线性地址是一一对应的。因此这两个页都在内核的线性地址空间内。  
{% codeblock lang:gas %}
    setup_paging:
    movl $1024*5,%ecx
    /* 5 pages - pg_dir+4 page tables*/
    xorl %eax,%eax
    xorl %edi,%edi
    /* pg_dir is at 0x000*/
    cld;rep;stosl
    movl $pg0+7,_pg_dir
    /* set present bit/user r/w*/
    movl $pg1+7,_pg_dir+4
    /*  --------- " " ---------*/
    movl $pg2+7,_pg_dir+8
    /*  --------- " " ---------*/
    movl $pg3+7,_pg_dir+12
    /*  --------- " " ---------*/
    movl $pg3+4092,%edi
    movl $0xfff007,%eax
    /*  16Mb - 4096 + 7 (r/w user,p)*/
    std
    1: stosl
    /* fill pages backwards - more efficient :-)*/
    subl $0x1000,%eax  
    jge 1b
{% endcodeblock %}  

# 16
>**假设：经过一段时间的运行，操作系统中已经有5个进程在运行，且内核分别为进程4、进程5分别创建了第一个页表，这两个页表在谁的线性地址空间？用图表示这两个页表在线性地址空间和物理地址空间的映射关系。**

两个页表均占用内核的线性地址空间

# 17
>**进程0开始创建进程1，调用了fork()，跟踪代码时我们发现，fork代码执行了两次，第一次，跳过init()直接执行了for(;;) pause()，第二次执行fork代码后，执行了init()。奇怪的是，我们在代码中并没有看见向后的goto语句，也没有看到循环语句，是什么原因导致反复执行？请说明理由，并给出代码证据。**

大致过程是：进程0在创建进程1时，判断条件中执行了第一次的`fork()`，这个时候没有写时复制，不能执行需要栈空间的函数。因此按照之前的定义
{% codeblock lang:c%}
static inline _syscall0(int, fork)
{% endcodeblock %}
`fork()`应该执行`_syscall0`中的`fork(void)`。经过一系列汇编代码的嵌入，最终会有这样的函数形式：
{% codeblock lang:c %}
int fork(void)
{
long __res;
__asm__ volatile("int $0x80"

    : "=a" (__res)
    : "0" (__NR_ fork));    

    if (__res >= 0)
    return (int) __res;
    errno= -__res;
    return -1；
}
{% endcodeblock %}
可见函数中调用了 int 0x80，显然需要各种压栈（按照顺序是：CPU硬件自动压栈：ss,esp,eflags,cs,eip；_system_call压栈：ds,es,fs,edx,ecx,ebx;`_sys_call_table`自动压栈对应的参数：long none；`_sys_fork`压栈：gs,esi,edi,ebp,eax（对应nr））。其中重要的是将eip的值设置为了返回之后的下一行，即
    if (__res >= 0)
之后调用`copy_process()`所用的所有参数，就是上面压栈的那些。`copy_process()`将这些寄存器的内容复制给了进程1的tss，值得注意的一点是，并不是所有的都复制了，其中进程1的eax就手动赋了0，而进程0是1。经过一系列分页设置、共享文件、设置GDT、修改状态之后，中断恢复，回到eip所指向的那条指令。此时eax存储的是1，返回给if判断不通过，于是执行`for(;;) pause`。之后通过进程调度进程1开始运行时，同样到了
{% codeblock lang:c%}
if(!fork())
{% endcodeblock %}
这里，执行了第二次`fork()`。由于进程1的tss中eax手动赋了0，于是在上面第二次int 0x80返回后，`__res=0`,返回给if语句后判断通过，就执行了`init()`。

# 18
>**copy_process函数的参数最后五项是：long eip,long cs,long eflags,long esp,long ss。查看栈结构确实有这五个参数，奇怪的是其他参数的压栈代码都能找得到，确找不到这五个参数的压栈代码，反汇编代码中也查不到，请解释原因。**

是由int 0x80在中断时通过cpu硬件自动压栈的。并不会体现在代码上。见20题。

# 19
>**为什么static inline _syscall0(type,name)中需要加上关键字inline？**

从内核空间创建进程将导致没有写时复制，直到执行一个execve调用。这可能给堆栈带来问题。处理方法是在`fork()`调用之后，禁止`main()`使用任何堆栈。因此就不能进行函数调用，这样`fork()`就也只能使用inline代码。否则`main()`中的其他代码运行时有可能再开辟堆栈空间污染原有栈数据。

# 20
>**根据代码详细说明copy_process函数的所有参数是如何形成的？**

`copy_process`的所有参数都是由之前的代码累积压栈得到的。
代码证据：
{% codeblock lang:gas %}
;代码路径：kernel/system_call.s:
_system_call:
    cmpl $nr_system_calls-1, %eax
    ja bad_sys_call
    push %ds
    push %es
    push %fs
    pushl %edx
    pushl %ecx
    pushl %ebx
    ...
{% endcodeblock %}
{% codeblock lang:gas %}
_sys_fork:
    call _find_empty_process
    testl %eax, %eax
    js 1f
    push %gs
    pushl %esi
    pushl %edi
    pushl %ebp
    pushl %eax
    call _copy_process
    ...
{% endcodeblock %}
其中最后压栈的eax是`find_empty_process()`返回的任务号，就是`copy_process()`函数的第一个参数int nr，以及int 0x80在中断时自动压栈的eip，cs，eflags，esp，ss，这些一起构成了`copy_process()`函数的第所有参数。

# 21
>**根据代码详细分析，进程0如何根据调度第一次切换到进程1的。**

`fork()`->`_syscall0`->int 0x80->`_sys_call`->`sys_fork`->`copy_process`->`get_free_page`->`copy_mem`->`get_free_page`->进程0怠速：`pause()`->`schedule()`->判断`if(!fork())`到`init()`->设置硬盘信息、建立缓冲区，开始执行。82-110页

# 22
>**内核的线性地址空间是如何分页的？画出从0x000000开始的7个页（包括页目录表、页表所在页）的挂接关系图，就是页目录表的前四个页目录项、第一个个页表的前7个页表项指向什么位置？给出代码证据。**

首先是1个页的也目录表，然后是4个页的页表，然后是若干个页。
页目录表的第一项指向第一个页表，以此类推，第四项指向第四个页表。
页表的第一个页表项指向第1个页，即页0，也就是页目录表所在的页。第二项指向自己，第三项指向第二个页表，以此类推。之后的页表项指向之后的页。

# 23
>**用文字和图说明中断描述符表是如何初始化的，可以举例说明（比如：set_trap_gate(0,&divide_error)），并给出代码证据。**

初始化中断描述符表即将中断服务程序与中断描述符表中的项一一对应。
`set_trap_gate(0,&divede_error)`对应宏函数
{% codeblock lang:c %}
#define _set_gate(gate_addr,type,dp1,addr) \
__asm__("movw %%dx, %%ax\n\t") \
        "movw %0, %%dx\n\t" \
        "movl %%eax, %1\n\t" \
        "movl %%edx, %2" \
        : \
    : "i" ((short) (0x8000 + (dpl<<13) + (type<<8))), \
        "o" (*((char *) (gate_addr))), \
        "o" (*(4+(char *) (gate_addr))), \
        "d" ((char *) (addr)), "a" (0x00080000)
    ...
{% endcodeblock %}
{% codeblock lang:c %}
#define set_trap_gate(n,addr)
    _set_gate(&idt[n],15,0,addr)
{% endcodeblock %}
55页

# 24
>**进程0 fork进程1之前，为什么先要调用move_to_user_mode()？用的是什么方法？解释其中的道理。**

因为在Linux-0.11中，除进程0之外，所有进程都是由一个已有进程在用户态下完成创建的。但是此时进程0还处于内核态，因此要调用`move_to_user_mode()`函数，模仿中断返回的方式，实现进程0的特权级从内核态转化为用户态。又因为在Linux-0.11中，转换特权级时采用中断和中断返回的方式，调用系统中断实现从3到0的特权级转换，中断返回时转换为3特权级。因此，进程0从0特权级到3特权级转换时采用的是模仿中断返回。

# 25
>**进程0创建进程1时调用copy_process函数，在其中直接、间接调用了两次get_free_page函数，在物理内存中获得了两个页，分别用作什么？是怎么设置的？给出代码证据。**

第一次是创建进程1的tss和内核态栈：
{% codeblock lang:c %}
p = (struct task_struct *) get_free_page();
*p = *current
p->tss.esp0 = PAGE_SIZE + (long) p;
{% endcodeblock %}
第二次是位进程1创建第一个页表：
{% codeblock lang:c %}
if (!(to_page_table = (unsigned long *) get_free_page()))
    return -1;
*to_dir = ((unsigned long) to_page_table) | 7;
{% endcodeblock %}

# 26
>**在IA-32中，有大约20多个指令是只能在0特权级下使用，其他的指令，比如cli，并没有这个约定。奇怪的是，在Linux0.11中，在3特权级的进程代码并不能使用cli指令，会报特权级错误，这是为什么？请解释并给出代码证据。**


*   cli指令用于复位IF标志位。在IA-32体系结构中规定，只有当CPL小于或等于IOPL时才可以执行该指令。如果在CPL大于IOPL的情况下执行，将会产生一个一般保护异常（#GP）。保护异常(#GP)是interrupt 0x13， 在`trap_init()`中设置
    --set_trap_gate(13,&general_protection);
*   IA32硬件规定，在执行CLI指令的时候，当前代码的特权级数值上必须不高于当前EFLAGS寄存器中IOPL字段的值。进程0的EFLAGS值设置为0，后续进程如果没有改动也是0，IOPL=0。因此特权级3的代码不能用cli。

# 27
>**根据代码详细分析操作系统是如何获得一个空闲页的。**

{% codeblock lang:gas %}
unsigned long get_free_page(void)
{
register unsigned long __res asm("ax");

__asm__("std;repne;scasb\n\t")

        "jne 1f\n\t"
        "movb $1, 1(%%edi)\n\t"

        "sall $12, %%ecx\n\t"
        "addl %2,%%ecx\n\t"
        "movl %%ecx,%%edx\n\t"
        "movl $1024,%%ecx\n\t"
        "leal 4092(%%eax),%%edi\n\t"

}
{% endcodeblock %}
89页 注释：首先反向扫描串`mem map[]`，`al(0)`与di不等则重复寻找引用对数为0的项。若找不到空闲页，跳转到1。否则将1赋值给edi+1的位置，使，在`mem map[]`中，将找到0的项的引用计数置1。接着将ecx算数左移12位，即页的相对地址。LOW MEN + ecx作为页的物理地址。将edx + 4 KB的有效地址赋给edi。将eax（即`"0"(0)`），目的是页面清零。

# 28
>**用户进程自己设计一套LDT表，并与GDT挂接，是否可行，为什么？**

用户代码段的特权级都是3，内核特权级是0，跨特权长跳转是被禁止的，不管是0跳3还是3跳0。这一特权级壁垒，是由CPU硬件做到的。GDT，LDT这两个数据结构被设置在内核数据区，是0特权级，只有0特权级才能修改设置GDT，LDT。而用户进程自己设计的LDT不会被CPU承认，因为真正有效的GDT、LDT需要挂接在CPU的GDTR、LDTR上，CPU只承认它们指向的数据结构，并且设置GTDR、LDTR的操作也能且只能在0特权级下进行。
259页

# 29
>**保护模式下，线性地址到物理地址的转化过程是什么？**

保护模式：已经打开PE；
未打开PG：恒等映射，由于Linux 0.11的特性，只能在16MB空间内寻址；
打开PG：进行32位寻址，在IA-32体系下能够支持最多4GB物理内存。32位的线性地址需要通过MMU进行解析，以页目录表-页表-页面三级映射的形式进行线性地址-物理地址的转换。类似于GDT和GDTR，页目录表的基址在CPU中也有相应的空间存储，即CR3。MMU在解析线性地址时，首先查询CR3找到页目录表，根据前10位找到页目录项，该项内记载着页表的**物理地址值**，根据接下来的10位找到页表项，该项记载着页面的**物理地址**。接下来的12位表示页面内的偏移物理地址，这样就完成了线性地址到物理地址经过页目录表-页表-页面的三级映射。

# 30
>**为什么get_free_page()将新分配的页面清0？**

防止该位置之前已经存在的垃圾数据对新进程造成影响。

# 31
>**内核和普通用户进程并不在一个线性地址空间内，为什么仍然能够访问普通用户进程的页面？**

虽然它们的线性地址空间不同，但是它们映射的物理地址可能重合。或者通过页面共享，访问同样的内容。但是不论是哪种方式，都需要对页面的特权级和读写保护进行严格的控制。

# 32
>**详细分析一个进程从创建、加载程序、执行、退出的全过程。**

*   创建
    首先，一个进程的创建必是由某个父进程来执行的。

    用户创建进程，一般是shell创建。假设硬盘上有一可执行文件p，用户输入shell指令后，系统响应该指令并开始创建进程，调用`fork`，进入int 0x80中断。首先在task[64]中申请进程槽（项），并获得一个进程号，如5。随后根据该项号确定在哪个线性地址空间以及LDT和TSS的对应关系。

    接下来创建进程skeleton。`copy_process()`调用`get_free_page`在内核线性地址空间中申请了task_struct和内核栈。接下来父进程shell将自己的task_stuct复制给p，因为这是一个不同的进程，还要进行个性化设置。之前要将其设置为不可中断等待状态。设置好包括进程号、父进程、TSS等内容之后，还要复制p本身的代码。这就要为进程分段，确定线性地址空间，即设置段基址和段限长。之前为了共享父进程的代码和数据，LDT都是继承父进程的，并且分页也是共享父进程的，只是创建了另一套页目录表项和页表项，指向父进程页面。文件同样继承父进程的。
    接下来将TSS和LDT挂载在GDT指定位置处，建立段一级保护。最后设置其为就绪态。准备参加调度。
*   加载
    首先检查页面空间、文件，确定其格式和规范合法正确。随后着手与父进程脱离关系，清空页目录表项和页表。重新设置LDT，调整task_struct。此时p没有页，执行将产生缺页中断。`trap_init`引导缺页中断，`_page_fault`中`_do_no_page`调用缺页处理函数,`_do_wp_page`调用写保护处理函数。首先确认缺页中断是加载进程引起的，接着确认是否可以通过共享获得页，`for`循环连读4个块。`block+1`让出文件头，`bread_page`是读一个页到缓冲区，占用4个块。读盘动作总要先申请缓冲区，一次从文件上读取一个页大小。缓冲区操作建立：`bh``request`。如果页不够用，就继续缺页中断，直至加载完毕。
*   执行
    开辟栈空间供其使用，运行结束清空栈空间
*   退出
    由进程自身发起。链接器在应用程序上加上`_exit`。直接贴机器码。走int 0x80 system_call那一套。`do_exit`执行各种内存释放操作。进程本身的退出还是要由父进程操作。此时只是发出请求并执行自身能够完成的任务：释放内存，清空进程槽，清空文件访问关系等。直至将进程状态改为`TASK_ZOMBIE`。最后不能使用`iret`而是调用`tell_father`。
    通过进程通信机制向父进程发送退出信号，等待父进程调用int 0x80时接收信号。当父进程调度时，`do_signal`将处理信号，随后清栈。由于`do_signal`的作用（复制内核栈的内容到用户栈，修改内核栈使进程转向），父进程int 0x80返回后指向`wait`，引发`sys_waitpid`，开始清理，完成后根据用户栈的内容回到父进程用户态继续执行，至此子进程退出彻底完成。

# 33
>**详细分析多个进程（无父子关系）共享一个可执行程序的完整过程。**

`share_page`与`try_to_share`
首先调用`share_page`检查文件是否可执行、是否有其他进程打开过该文件。然后遍历task[]找到第一个打开该文件的进程，确认进程合法性之后调用`try_to_share`共享这个页。确认P位为1，D位为0，否则重新读盘；然后开启写保护读取该页。

# 34
>**缺页中断是如何产生的，页写保护中断是如何产生的，操作系统是如何处理的？**

P位为1引发`trap_init`中关于第14位的缺页中断。调用`_do_no_page`处理函数、`_do_wp_page`写保护函数。见doc

# 35
>**为什么要设计缓冲区，有什么好处？**

缓冲区的本质是一块内存，核心思想是资源的“复用”，目的是提高资源访问速度。因为内存访问速度比硬盘的访问速度快得多，如果同一个资源多次被读取，那么由硬盘一次性写入内存之后再多次从内存读出，将比每次都从硬盘读取快很多，使得系统执行效率得到很大的提升.

# 36
>**操作系统如何利用buffer_head中的 b_data，b_blocknr，b_dev，b_uptodate，b_dirt，b_count，b_lock，b_wait管理缓冲块的？**


*  指针b_data指向数据块。
*  设备号b_blocknr和块号b_dev经常连用。一个块只有一个管理信息，存入的数据归属具有唯一性。
*  整个硬盘空间，每个块都是独立并且唯一存在的，通过设备号和块号两个参数唯一确定。
*  计数器b_count计数此时正在操作缓冲块的进程的个数。由于缓冲区没有撤销废除机制，所以只能说b_count=0的缓冲块，可以被替换，但并不是必须且立即的。
*  b_dirt脏位，表示块已经被写过。
*  b_lock表示当前块正在被操作，读或者写。
*  b_uptodate表示更新位。

由进程到缓冲区/缓冲块之间的关系，由buffer_head管理，由缓冲区到外设io的关系，由request项管理，有单独的一段程序实现。

进程首先查询数据是否在缓冲区中存在。如果有就直接读。如果没有，看是否有空缓冲区，如果有建立缓冲块并与请求项建立关系。

分开管理有利于获得高效率。
